{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vic\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas_profiling\\plot.py:15: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"c:\\users\\vic\\appdata\\local\\programs\\python\\python37-32\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"c:\\users\\vic\\appdata\\local\\programs\\python\\python37-32\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\users\\vic\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\users\\vic\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\users\\vic\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\users\\vic\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\users\\vic\\appdata\\local\\programs\\python\\python37-32\\lib\\asyncio\\base_events.py\", line 523, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\users\\vic\\appdata\\local\\programs\\python\\python37-32\\lib\\asyncio\\base_events.py\", line 1758, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\users\\vic\\appdata\\local\\programs\\python\\python37-32\\lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\users\\vic\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 122, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"c:\\users\\vic\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\users\\vic\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"c:\\users\\vic\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"c:\\users\\vic\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"c:\\users\\vic\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"c:\\users\\vic\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"c:\\users\\vic\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"c:\\users\\vic\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"c:\\users\\vic\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"c:\\users\\vic\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"c:\\users\\vic\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"c:\\users\\vic\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"c:\\users\\vic\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"c:\\users\\vic\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-c4bfd0ee3fb9>\", line 4, in <module>\n",
      "    import seaborn as sns\n",
      "  File \"c:\\users\\vic\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\seaborn\\__init__.py\", line 6, in <module>\n",
      "    from .rcmod import *\n",
      "  File \"c:\\users\\vic\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\seaborn\\rcmod.py\", line 5, in <module>\n",
      "    from . import palettes, _orig_rc_params\n",
      "  File \"c:\\users\\vic\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\seaborn\\palettes.py\", line 12, in <module>\n",
      "    from .utils import desaturate, set_hls_values, get_color_cycle\n",
      "  File \"c:\\users\\vic\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\seaborn\\utils.py\", line 11, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "  File \"c:\\users\\vic\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\matplotlib\\pyplot.py\", line 71, in <module>\n",
      "    from matplotlib.backends import pylab_setup\n",
      "  File \"c:\\users\\vic\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\matplotlib\\backends\\__init__.py\", line 16, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  matplotlib.use(BACKEND)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\VIC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\VIC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_profiling\n",
    "from nltk.corpus import stopwords\n",
    "%matplotlib inline\n",
    "\n",
    "file_data=pd.read_csv(\"Womens Clothing E-Commerce Reviews.csv\",index_col=False)\n",
    "data_fields=['Review Text','Rating','Recommended IND','Positive Feedback Count','Division Name','Department Name','Class Name']\n",
    "mydata=pd.DataFrame(data=file_data,columns=data_fields)\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "import string\n",
    "def text_process(review):\n",
    "    nopunc=[word for word in review if word not in string.punctuation]\n",
    "    nopunc=''.join(nopunc)\n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
    "\n",
    "mydata['Review Text'].head(5).apply(text_process)\n",
    "\n",
    "mydata=mydata.dropna(axis=0,how='any')\n",
    "selected_rating_data = mydata[(mydata['Rating'] == 1) | (mydata['Rating'] == 5)]\n",
    "X_review=selected_rating_data['Review Text']\n",
    "y=selected_rating_data['Rating']\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow_transformer=CountVectorizer(analyzer=text_process).fit(X_review)\n",
    "\n",
    "X_review = bow_transformer.transform(X_review)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_review, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "X_resampled, y_resampled = SMOTE().fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({5: 8773, 1: 8773})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "collections.Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 164   87]\n",
      " [  70 3684]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.65      0.68       251\n",
      "          5       0.98      0.98      0.98      3754\n",
      "\n",
      "avg / total       0.96      0.96      0.96      4005\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictSVM=clf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, predictSVM))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, predictSVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(52, 52, 52), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(52,52,52),max_iter=500)\n",
    "\n",
    "mlp.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 155   96]\n",
      " [  32 3722]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.83      0.62      0.71       251\n",
      "          5       0.97      0.99      0.98      3754\n",
      "\n",
      "avg / total       0.97      0.97      0.97      4005\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictionsANN = mlp.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, predictionsANN))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictionsANN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  86  165]\n",
      " [  15 3739]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.85      0.34      0.49       251\n",
      "          5       0.96      1.00      0.98      3754\n",
      "\n",
      "avg / total       0.95      0.96      0.95      4005\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictNB=nb.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, predictNB))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, predictNB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=50, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression(penalty='l2',solver='newton-cg',max_iter=50, multi_class='ovr')\n",
    "LR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 166   85]\n",
      " [  30 3724]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.85      0.66      0.74       251\n",
      "          5       0.98      0.99      0.98      3754\n",
      "\n",
      "avg / total       0.97      0.97      0.97      4005\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictLR=LR.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, predictLR))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, predictLR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96182635, 0.96479401, 0.96928839, 0.95955056, 0.96104869,\n",
       "       0.96104869, 0.96104869, 0.95802099, 0.95352324, 0.96626687])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(clf, X_review, y, cv=10)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95134731, 0.96404494, 0.96179775, 0.95580524, 0.95205993,\n",
       "       0.96779026, 0.96104869, 0.96626687, 0.95652174, 0.95127436])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(nb, X_review, y, cv=10)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96706587, 0.96928839, 0.97303371, 0.96629213, 0.96479401,\n",
       "       0.97303371, 0.96254682, 0.96326837, 0.96251874, 0.97001499])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(LR, X_review, y, cv=10)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(mlp, X_review, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='linear')\n",
    "from sklearn.model_selection import train_test_split\n",
    "for i in range(10):    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_review, y, test_size=0.3, random_state=101)\n",
    "    X_resampled, y_resampled = SMOTE().fit_sample(X_train, y_train)\n",
    "    \n",
    "\n",
    "    clf.fit(X_resampled, y_resampled) \n",
    "    predictSVM=clf.predict(X_test)\n",
    "\n",
    "    print(confusion_matrix(y_test, predictSVM))\n",
    "    print('\\n')\n",
    "    print(classification_report(y_test, predictSVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(13,13,13),max_iter=500)\n",
    "for i in range(10):  \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_review, y, test_size=0.3, random_state=101)\n",
    "    X_resampled, y_resampled = SMOTE().fit_sample(X_train, y_train)\n",
    "    \n",
    "   \n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(13,13,13),max_iter=500)\n",
    "    mlp.fit(X_resampled,y_resampled)\n",
    "    predictionsANN = mlp.predict(X_test)\n",
    "    \n",
    "    print(confusion_matrix(y_test, predictionsANN))\n",
    "    print('\\n')\n",
    "    print(classification_report(y_test, predictionsANN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "for i in range(10): \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_review, y, test_size=0.3, random_state=101)\n",
    "    X_resampled, y_resampled = SMOTE().fit_sample(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(X_resampled, y_resampled)\n",
    "    predictNB=nb.predict(X_test)\n",
    "    \n",
    "    print(confusion_matrix(y_test, predictNB))\n",
    "    print('\\n')\n",
    "    print(classification_report(y_test, predictNB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression(penalty='l2',solver='newton-cg',max_iter=50, multi_class='ovr')\n",
    "for i in range(10): \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_review, y, test_size=0.3, random_state=101)\n",
    "    X_resampled, y_resampled = SMOTE().fit_sample(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    LR = LogisticRegression(penalty='l2',solver='newton-cg',max_iter=50, multi_class='ovr')\n",
    "    LR.fit(X_resampled, y_resampled)\n",
    "    predictLR=LR.predict(X_test)\n",
    "    \n",
    "    print(confusion_matrix(y_test, predictLR))\n",
    "    print('\\n')\n",
    "    print(classification_report(y_test, predictLR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bow_transformer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.nan)\n",
    "X_review.todense()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
